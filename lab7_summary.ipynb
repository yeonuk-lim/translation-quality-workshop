{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Lab 7: ì¢…í•© ë¶„ì„\n",
    "\n",
    "\n",
    "\n",
    " ì›Œí¬ìƒµ ì „ì²´ ê²°ê³¼ë¥¼ ì¢…í•© ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    " ## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "\n",
    "\n",
    " - ì „ì²´ Lab ê²°ê³¼ í†µí•© ë¶„ì„\n",
    "\n",
    " - Before/After í’ˆì§ˆ í–¥ìƒ ì‹œê°í™”\n",
    "\n",
    " - ì‹¤ë¬´ ì ìš© ë°©ì•ˆ ì •ë¦¬\n",
    "\n",
    "\n",
    "\n",
    " ## ì›Œí¬ìƒµ ì „ì²´ íë¦„\n",
    "\n",
    "\n",
    "\n",
    " ```\n",
    "\n",
    " Lab 1: í™˜ê²½ ì„¤ì • âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 2: ë²ˆì—­ ê¸°ë²• ë¹„êµ âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 3: í’ˆì§ˆ í‰ê°€ - ì¶©ì‹¤ë„ âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 4: í’ˆì§ˆ í‰ê°€ - ìš©ì–´ ì¼ê´€ì„± âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 5: í’ˆì§ˆ í‰ê°€ - ë¬¸í™”/í†¤ âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 6: í”¼ë“œë°± ê¸°ë°˜ ì¬ë²ˆì—­ âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 7: ì¢…í•© ë¶„ì„ (í˜„ì¬)\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.1 í™˜ê²½ ì„¤ì • ë° ì „ì²´ ê²°ê³¼ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"lab_outputs\"\n",
    "\n",
    "def load_results(filename: str) -> dict:\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  Lab ê²°ê³¼ ë¡œë“œ\n",
    "print(\"ì „ì²´ Lab ê²°ê³¼ ë¡œë“œ ì¤‘...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lab 2: ë²ˆì—­ ê²°ê³¼\n",
    "zero_shot = load_results(\"translations_zero_shot.json\")\n",
    "few_shot = load_results(\"translations_few_shot.json\")\n",
    "glossary = load_results(\"translations_glossary.json\")\n",
    "\n",
    "# Lab 3-5: í‰ê°€ ê²°ê³¼\n",
    "faithfulness = load_results(\"eval_faithfulness.json\")\n",
    "terminology = load_results(\"eval_terminology.json\")\n",
    "culture_tone = load_results(\"eval_culture_tone.json\")\n",
    "\n",
    "# Lab 6: ì¬ë²ˆì—­ ê²°ê³¼\n",
    "us_targeted = load_results(\"translations_us_targeted.json\")\n",
    "\n",
    "# GB ê²°ê³¼ (ë¯¸ì…˜ ì™„ë£Œ ì‹œ)\n",
    "try:\n",
    "    gb_targeted = load_results(\"translations_gb_targeted.json\")\n",
    "    gb_loaded = True\n",
    "    print(\"âœ“ GB ì˜ì–´ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ\")\n",
    "except:\n",
    "    gb_loaded = False\n",
    "    print(\"â–³ GB ì˜ì–´ ê²°ê³¼ ì—†ìŒ (ë¯¸ì…˜ ë¯¸ì™„ë£Œ)\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.2 ë²ˆì—­ ê¸°ë²•ë³„ í‰ê°€ ì ìˆ˜ ë¹„êµ (Lab 3-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 3-5 í‰ê°€ ì ìˆ˜ ì¶”ì¶œ\n",
    "def extract_scores(eval_data: dict) -> dict:\n",
    "    \"\"\"í‰ê°€ ë°ì´í„°ì—ì„œ ê¸°ë²•ë³„ í‰ê·  ì ìˆ˜ ì¶”ì¶œ\"\"\"\n",
    "    scores = {}\n",
    "    for method in [\"zero_shot\", \"few_shot\", \"glossary\"]:\n",
    "        if method in eval_data:\n",
    "            method_scores = [item[\"score\"] for item in eval_data[method]]\n",
    "            scores[method] = sum(method_scores) / len(method_scores)\n",
    "    return scores\n",
    "\n",
    "faith_scores = extract_scores(faithfulness)\n",
    "term_scores = extract_scores(terminology)\n",
    "tone_scores = extract_scores(culture_tone)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ë²ˆì—­ ê¸°ë²•ë³„ í‰ê°€ ì ìˆ˜ (Lab 3-5)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'ê¸°ë²•':<15} {'ì¶©ì‹¤ë„':<12} {'ìš©ì–´':<12} {'í†¤':<12} {'í‰ê· ':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for method in [\"zero_shot\", \"few_shot\", \"glossary\"]:\n",
    "    faith = faith_scores.get(method, 0)\n",
    "    term = term_scores.get(method, 0)\n",
    "    tone = tone_scores.get(method, 0)\n",
    "    avg = (faith + term + tone) / 3\n",
    "    \n",
    "    method_name = {\"zero_shot\": \"Zero-shot\", \"few_shot\": \"Few-shot\", \"glossary\": \"ìš©ì–´ì§‘\"}[method]\n",
    "    print(f\"{method_name:<15} {faith:<12.2f} {term:<12.2f} {tone:<12.2f} {avg:<12.2f}\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.3 Lab 6 ì¬ë²ˆì—­ ê²°ê³¼ vs ê¸°ì¡´ ê²°ê³¼ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US íƒ€ê²ŸíŒ… ê²°ê³¼\n",
    "us_summary = us_targeted.get(\"summary\", {})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Lab 6 ì¬ë²ˆì—­ ê²°ê³¼ (US ì˜ì–´)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\në ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„: {us_summary.get('similarity_avg', 0):.2f}/5\")\n",
    "print(f\"ì¶©ì‹¤ë„: {us_summary.get('faithfulness_avg', 0):.2f}/5\")\n",
    "print(f\"ìš©ì–´ ì¼ê´€ì„±: {us_summary.get('terminology_avg', 0):.2f}/5\")\n",
    "print(f\"í†¤/ìŠ¤íƒ€ì¼: {us_summary.get('tone_avg', 0):.2f}/5\")\n",
    "\n",
    "us_total = (\n",
    "    us_summary.get('faithfulness_avg', 0) + \n",
    "    us_summary.get('terminology_avg', 0) + \n",
    "    us_summary.get('tone_avg', 0)\n",
    ") / 3\n",
    "print(f\"\\ní’ˆì§ˆ í‰ê· : {us_total:.2f}/5\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB ê²°ê³¼ (ë¯¸ì…˜ ì™„ë£Œ ì‹œ)\n",
    "if gb_loaded:\n",
    "    gb_summary = gb_targeted.get(\"summary\", {})\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Lab 6 ì¬ë²ˆì—­ ê²°ê³¼ (GB ì˜ì–´) - ë¯¸ì…˜ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\në ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„: {gb_summary.get('similarity_avg', 0):.2f}/5\")\n",
    "    print(f\"ì¶©ì‹¤ë„: {gb_summary.get('faithfulness_avg', 0):.2f}/5\")\n",
    "    print(f\"ìš©ì–´ ì¼ê´€ì„±: {gb_summary.get('terminology_avg', 0):.2f}/5\")\n",
    "    print(f\"í†¤/ìŠ¤íƒ€ì¼: {gb_summary.get('tone_avg', 0):.2f}/5\")\n",
    "    \n",
    "    gb_total = (\n",
    "        gb_summary.get('faithfulness_avg', 0) + \n",
    "        gb_summary.get('terminology_avg', 0) + \n",
    "        gb_summary.get('tone_avg', 0)\n",
    "    ) / 3\n",
    "    print(f\"\\ní’ˆì§ˆ í‰ê· : {gb_total:.2f}/5\")\n",
    "    print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.4 Before/After ë¹„êµ: Zero-shot â†’ ì¬ë²ˆì—­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot vs US íƒ€ê²ŸíŒ… ë¹„êµ\n",
    "zero_avg = (faith_scores[\"zero_shot\"] + term_scores[\"zero_shot\"] + tone_scores[\"zero_shot\"]) / 3\n",
    "glossary_avg = (faith_scores[\"glossary\"] + term_scores[\"glossary\"] + tone_scores[\"glossary\"]) / 3\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Before/After í’ˆì§ˆ ë¹„êµ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'ë‹¨ê³„':<25} {'ì¶©ì‹¤ë„':<10} {'ìš©ì–´':<10} {'í†¤':<10} {'í‰ê· ':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Zero-shot (ì‹œì‘ì )\n",
    "print(f\"{'1. Zero-shot':<25} {faith_scores['zero_shot']:<10.2f} {term_scores['zero_shot']:<10.2f} {tone_scores['zero_shot']:<10.2f} {zero_avg:<10.2f}\")\n",
    "\n",
    "# Few-shot\n",
    "few_avg = (faith_scores[\"few_shot\"] + term_scores[\"few_shot\"] + tone_scores[\"few_shot\"]) / 3\n",
    "print(f\"{'2. Few-shot':<25} {faith_scores['few_shot']:<10.2f} {term_scores['few_shot']:<10.2f} {tone_scores['few_shot']:<10.2f} {few_avg:<10.2f}\")\n",
    "\n",
    "# ìš©ì–´ì§‘ ì ìš©\n",
    "print(f\"{'3. ìš©ì–´ì§‘ ì ìš©':<25} {faith_scores['glossary']:<10.2f} {term_scores['glossary']:<10.2f} {tone_scores['glossary']:<10.2f} {glossary_avg:<10.2f}\")\n",
    "\n",
    "# US íƒ€ê²ŸíŒ… (ìµœì¢…)\n",
    "print(f\"{'4. US íƒ€ê²ŸíŒ… ì¬ë²ˆì—­':<25} {us_summary.get('faithfulness_avg', 0):<10.2f} {us_summary.get('terminology_avg', 0):<10.2f} {us_summary.get('tone_avg', 0):<10.2f} {us_total:<10.2f}\")\n",
    "\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# ê°œì„ ìœ¨ ê³„ì‚°\n",
    "improvement = ((us_total - zero_avg) / zero_avg) * 100 if zero_avg > 0 else 0\n",
    "print(f\"\\nğŸ“ˆ Zero-shot â†’ US íƒ€ê²ŸíŒ… ê°œì„ ìœ¨: {improvement:+.1f}%\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.5 ì‹œê°í™”: ë²ˆì—­ ê¸°ë²•ë³„ ì ìˆ˜ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§‰ëŒ€ ì°¨íŠ¸: ê¸°ë²•ë³„ í‰ê°€ ì ìˆ˜\n",
    "methods = [\"Zero-shot\", \"Few-shot\", \"Glossary\", \"US Targeted\"]\n",
    "faith_values = [\n",
    "    faith_scores[\"zero_shot\"],\n",
    "    faith_scores[\"few_shot\"],\n",
    "    faith_scores[\"glossary\"],\n",
    "    us_summary.get(\"faithfulness_avg\", 0)\n",
    "]\n",
    "term_values = [\n",
    "    term_scores[\"zero_shot\"],\n",
    "    term_scores[\"few_shot\"],\n",
    "    term_scores[\"glossary\"],\n",
    "    us_summary.get(\"terminology_avg\", 0)\n",
    "]\n",
    "tone_values = [\n",
    "    tone_scores[\"zero_shot\"],\n",
    "    tone_scores[\"few_shot\"],\n",
    "    tone_scores[\"glossary\"],\n",
    "    us_summary.get(\"tone_avg\", 0)\n",
    "]\n",
    "\n",
    "x = range(len(methods))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar([i - width for i in x], faith_values, width, label='Faithfulness', color='#3498db')\n",
    "bars2 = ax.bar(x, term_values, width, label='Terminology', color='#2ecc71')\n",
    "bars3 = ax.bar([i + width for i in x], tone_values, width, label='Tone', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Translation Method')\n",
    "ax.set_ylabel('Score (0-5)')\n",
    "ax.set_title('Translation Quality by Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 5.5)\n",
    "\n",
    "# ì ìˆ˜ í‘œì‹œ\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"chart_method_comparison.png\"), dpi=150)\n",
    "plt.show()\n",
    "print(f\"âœ“ ì°¨íŠ¸ ì €ì¥: {OUTPUT_DIR}/chart_method_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.6 ì‹œê°í™”: í’ˆì§ˆ ê°œì„  ì¶”ì´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì¸ ì°¨íŠ¸: ë‹¨ê³„ë³„ í’ˆì§ˆ ê°œì„ \n",
    "stages = [\"Zero-shot\", \"Few-shot\", \"Glossary\", \"US Targeted\"]\n",
    "avg_scores = [zero_avg, few_avg, glossary_avg, us_total]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(stages, avg_scores, marker='o', linewidth=2, markersize=10, color='#3498db')\n",
    "\n",
    "ax.set_xlabel('Translation Stage')\n",
    "ax.set_ylabel('Average Score (0-5)')\n",
    "ax.set_title('Translation Quality Improvement')\n",
    "ax.set_ylim(0, 5.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ì ìˆ˜ í‘œì‹œ\n",
    "for i, (stage, score) in enumerate(zip(stages, avg_scores)):\n",
    "    ax.annotate(f'{score:.2f}',\n",
    "                xy=(i, score),\n",
    "                xytext=(0, 10),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"chart_improvement_trend.png\"), dpi=150)\n",
    "plt.show()\n",
    "print(f\"âœ“ ì°¨íŠ¸ ì €ì¥: {OUTPUT_DIR}/chart_improvement_trend.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.7 US vs GB ë¹„êµ (ë¯¸ì…˜ ì™„ë£Œ ì‹œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gb_loaded:\n",
    "    # US vs GB ë¹„êµ ì°¨íŠ¸\n",
    "    categories = [\"Similarity\", \"Faithfulness\", \"Terminology\", \"Tone\"]\n",
    "    us_values = [\n",
    "        us_summary.get(\"similarity_avg\", 0),\n",
    "        us_summary.get(\"faithfulness_avg\", 0),\n",
    "        us_summary.get(\"terminology_avg\", 0),\n",
    "        us_summary.get(\"tone_avg\", 0)\n",
    "    ]\n",
    "    gb_values = [\n",
    "        gb_summary.get(\"similarity_avg\", 0),\n",
    "        gb_summary.get(\"faithfulness_avg\", 0),\n",
    "        gb_summary.get(\"terminology_avg\", 0),\n",
    "        gb_summary.get(\"tone_avg\", 0)\n",
    "    ]\n",
    "    \n",
    "    x = range(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    bars1 = ax.bar([i - width/2 for i in x], us_values, width, label='US English', color='#3498db')\n",
    "    bars2 = ax.bar([i + width/2 for i in x], gb_values, width, label='GB English', color='#e74c3c')\n",
    "    \n",
    "    ax.set_xlabel('Evaluation Category')\n",
    "    ax.set_ylabel('Score (0-5)')\n",
    "    ax.set_title('US vs GB English Translation Quality')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 5.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"chart_us_vs_gb.png\"), dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"âœ“ ì°¨íŠ¸ ì €ì¥: {OUTPUT_DIR}/chart_us_vs_gb.png\")\n",
    "else:\n",
    "    print(\"GB ì˜ì–´ ë¯¸ì…˜ì„ ì™„ë£Œí•˜ë©´ US vs GB ë¹„êµ ì°¨íŠ¸ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.8 í•­ëª©ë³„ ìƒì„¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•­ëª©ë³„ ì ìˆ˜ í…Œì´ë¸”\n",
    "print(\"=\" * 90)\n",
    "print(\"í•­ëª©ë³„ ìƒì„¸ ì ìˆ˜\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(f\"\\n{'ID':<35} {'Zero':<8} {'Few':<8} {'Gloss':<8} {'US':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, item in enumerate(faithfulness.get(\"zero_shot\", [])):\n",
    "    item_id = item[\"id\"]\n",
    "    \n",
    "    zero_score = faithfulness[\"zero_shot\"][i][\"score\"]\n",
    "    few_score = faithfulness[\"few_shot\"][i][\"score\"]\n",
    "    gloss_score = faithfulness[\"glossary\"][i][\"score\"]\n",
    "    \n",
    "    # US íƒ€ê²ŸíŒ… ì ìˆ˜\n",
    "    us_score = 0\n",
    "    for eval_item in us_targeted.get(\"quality_evals\", []):\n",
    "        if eval_item[\"id\"] == item_id:\n",
    "            us_score = eval_item[\"faithfulness\"][\"score\"]\n",
    "            break\n",
    "    \n",
    "    print(f\"{item_id:<35} {zero_score:<8} {few_score:<8} {gloss_score:<8} {us_score:<8}\")\n",
    "\n",
    "print(\"=\" * 90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.9 í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š ì›Œí¬ìƒµ í•µì‹¬ ì¸ì‚¬ì´íŠ¸\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[1] ë²ˆì—­ ê¸°ë²•ë³„ íš¨ê³¼\")\n",
    "print(f\"    â€¢ Zero-shot â†’ Few-shot: ìŠ¤íƒ€ì¼ ì¼ê´€ì„± í–¥ìƒ\")\n",
    "print(f\"    â€¢ Few-shot â†’ ìš©ì–´ì§‘: ë¸Œëœë“œ ìš©ì–´ ì •í™•ë„ í–¥ìƒ\")\n",
    "print(f\"    â€¢ ìš©ì–´ì§‘ â†’ íƒ€ê²ŸíŒ…: ì§€ì—­ë³„ ìµœì í™” ë‹¬ì„±\")\n",
    "\n",
    "print(\"\\n[2] í’ˆì§ˆ ê°œì„  íš¨ê³¼\")\n",
    "print(f\"    â€¢ ì‹œì‘ì  (Zero-shot): {zero_avg:.2f}/5\")\n",
    "print(f\"    â€¢ ìµœì¢… (US íƒ€ê²ŸíŒ…): {us_total:.2f}/5\")\n",
    "print(f\"    â€¢ ê°œì„ ìœ¨: {improvement:+.1f}%\")\n",
    "\n",
    "print(\"\\n[3] ë ˆí¼ëŸ°ìŠ¤ ê¸°ë°˜ ë¦¬ì†ŒìŠ¤ ì¶”ì¶œ\")\n",
    "print(f\"    â€¢ ìš©ì–´ì§‘ ìë™ ì¶”ì¶œë¡œ ì¼ê´€ì„± í™•ë³´\")\n",
    "print(f\"    â€¢ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ì¶œë¡œ í†¤ ì¼ì¹˜\")\n",
    "print(f\"    â€¢ ìƒˆë¡œìš´ ì–¸ì–´ ì¶”ê°€ ì‹œ ë™ì¼ ë°©ì‹ ì ìš© ê°€ëŠ¥\")\n",
    "\n",
    "print(\"\\n[4] í‰ê°€ í”¼ë“œë°± í™œìš©\")\n",
    "print(f\"    â€¢ Lab 3-5 í‰ê°€ ê²°ê³¼ë¥¼ ì¬ë²ˆì—­ì— ë°˜ì˜\")\n",
    "print(f\"    â€¢ ë¬¸ì œì  â†’ ê°œì„  â†’ ì¬í‰ê°€ ì‚¬ì´í´ êµ¬í˜„\")\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.10 ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ğŸš€ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[ë¹„ìš© ìµœì í™”]\")\n",
    "print(\"    â€¢ ì´ˆë²Œ ë²ˆì—­: Haiku (ë¹ ë¦„, ì €ë ´)\")\n",
    "print(\"    â€¢ í’ˆì§ˆ í‰ê°€: Sonnet (ê· í˜•)\")\n",
    "print(\"    â€¢ ìµœì¢… ê²€ìˆ˜: Sonnet ë˜ëŠ” Opus\")\n",
    "\n",
    "print(\"\\n[45ê°œ ì–¸ì–´ í™•ì¥ ì‹œ]\")\n",
    "print(\"    â€¢ ë ˆí¼ëŸ°ìŠ¤ ë°ì´í„°ì—ì„œ ìš©ì–´ì§‘/ìŠ¤íƒ€ì¼ ìë™ ì¶”ì¶œ\")\n",
    "print(\"    â€¢ ì–¸ì–´ë³„ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì •ì˜\")\n",
    "print(\"    â€¢ ë™ì¼í•œ í‰ê°€-í”¼ë“œë°±-ì¬ë²ˆì—­ íŒŒì´í”„ë¼ì¸ ì ìš©\")\n",
    "\n",
    "print(\"\\n[ìë™í™” íŒŒì´í”„ë¼ì¸]\")\n",
    "print(\"    1. ì›ë¬¸ ì…ë ¥\")\n",
    "print(\"    2. ìš©ì–´ì§‘/ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ë¡œë“œ\")\n",
    "print(\"    3. ë²ˆì—­ ì‹¤í–‰\")\n",
    "print(\"    4. í’ˆì§ˆ í‰ê°€ (ì¶©ì‹¤ë„/ìš©ì–´/í†¤)\")\n",
    "print(\"    5. ì ìˆ˜ < 4 â†’ í”¼ë“œë°± ê¸°ë°˜ ì¬ë²ˆì—­\")\n",
    "print(\"    6. ì ìˆ˜ >= 4 â†’ ìŠ¹ì¸\")\n",
    "\n",
    "print(\"\\n[ëª¨ë‹ˆí„°ë§]\")\n",
    "print(\"    â€¢ í‰ê·  ì ìˆ˜ ì¶”ì´\")\n",
    "print(\"    â€¢ ì¬ë²ˆì—­ ë¹„ìœ¨\")\n",
    "print(\"    â€¢ ì–¸ì–´ë³„/í•­ëª©ë³„ í’ˆì§ˆ ë¶„í¬\")\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.11 ìµœì¢… ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¢…í•© ë¦¬í¬íŠ¸ ì €ì¥\n",
    "summary_report = {\n",
    "    \"workshop_summary\": {\n",
    "        \"total_faq_items\": len(faithfulness.get(\"zero_shot\", [])),\n",
    "        \"translation_methods\": [\"zero_shot\", \"few_shot\", \"glossary\", \"us_targeted\"],\n",
    "        \"evaluation_types\": [\"faithfulness\", \"terminology\", \"culture_tone\"]\n",
    "    },\n",
    "    \"method_scores\": {\n",
    "        \"zero_shot\": {\n",
    "            \"faithfulness\": faith_scores[\"zero_shot\"],\n",
    "            \"terminology\": term_scores[\"zero_shot\"],\n",
    "            \"tone\": tone_scores[\"zero_shot\"],\n",
    "            \"average\": zero_avg\n",
    "        },\n",
    "        \"few_shot\": {\n",
    "            \"faithfulness\": faith_scores[\"few_shot\"],\n",
    "            \"terminology\": term_scores[\"few_shot\"],\n",
    "            \"tone\": tone_scores[\"few_shot\"],\n",
    "            \"average\": few_avg\n",
    "        },\n",
    "        \"glossary\": {\n",
    "            \"faithfulness\": faith_scores[\"glossary\"],\n",
    "            \"terminology\": term_scores[\"glossary\"],\n",
    "            \"tone\": tone_scores[\"glossary\"],\n",
    "            \"average\": glossary_avg\n",
    "        },\n",
    "        \"us_targeted\": us_summary\n",
    "    },\n",
    "    \"improvement\": {\n",
    "        \"from\": zero_avg,\n",
    "        \"to\": us_total,\n",
    "        \"percentage\": improvement\n",
    "    },\n",
    "    \"gb_completed\": gb_loaded\n",
    "}\n",
    "\n",
    "if gb_loaded:\n",
    "    summary_report[\"method_scores\"][\"gb_targeted\"] = gb_summary\n",
    "\n",
    "# ì €ì¥\n",
    "filepath = os.path.join(OUTPUT_DIR, \"summary_report.json\")\n",
    "with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary_report, f, ensure_ascii=False, indent=2)\n",
    "print(f\"âœ“ ì¢…í•© ë¦¬í¬íŠ¸ ì €ì¥: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7.12 ì›Œí¬ìƒµ ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ‰ Translation Quality Workshop ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[ì™„ë£Œëœ Lab]\")\n",
    "print(\"    âœ… Lab 1: í™˜ê²½ ì„¤ì •\")\n",
    "print(\"    âœ… Lab 2: ë²ˆì—­ ê¸°ë²• ë¹„êµ\")\n",
    "print(\"    âœ… Lab 3: í’ˆì§ˆ í‰ê°€ - ì¶©ì‹¤ë„\")\n",
    "print(\"    âœ… Lab 4: í’ˆì§ˆ í‰ê°€ - ìš©ì–´ ì¼ê´€ì„±\")\n",
    "print(\"    âœ… Lab 5: í’ˆì§ˆ í‰ê°€ - ë¬¸í™”/í†¤\")\n",
    "print(\"    âœ… Lab 6: í”¼ë“œë°± ê¸°ë°˜ ì¬ë²ˆì—­\")\n",
    "print(\"    âœ… Lab 7: ì¢…í•© ë¶„ì„\")\n",
    "\n",
    "print(\"\\n[ìƒì„±ëœ íŒŒì¼]\")\n",
    "print(f\"    ğŸ“ {OUTPUT_DIR}/\")\n",
    "print(\"    â”œâ”€â”€ translations_zero_shot.json\")\n",
    "print(\"    â”œâ”€â”€ translations_few_shot.json\")\n",
    "print(\"    â”œâ”€â”€ translations_glossary.json\")\n",
    "print(\"    â”œâ”€â”€ eval_faithfulness.json\")\n",
    "print(\"    â”œâ”€â”€ eval_terminology.json\")\n",
    "print(\"    â”œâ”€â”€ eval_culture_tone.json\")\n",
    "print(\"    â”œâ”€â”€ glossary_us.json\")\n",
    "print(\"    â”œâ”€â”€ style_guide_us.json\")\n",
    "print(\"    â”œâ”€â”€ translations_us_targeted.json\")\n",
    "if gb_loaded:\n",
    "    print(\"    â”œâ”€â”€ glossary_gb.json\")\n",
    "    print(\"    â”œâ”€â”€ style_guide_gb.json\")\n",
    "    print(\"    â”œâ”€â”€ translations_gb_targeted.json\")\n",
    "print(\"    â”œâ”€â”€ chart_method_comparison.png\")\n",
    "print(\"    â”œâ”€â”€ chart_improvement_trend.png\")\n",
    "if gb_loaded:\n",
    "    print(\"    â”œâ”€â”€ chart_us_vs_gb.png\")\n",
    "print(\"    â””â”€â”€ summary_report.json\")\n",
    "\n",
    "print(\"\\n[ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ]\")\n",
    "print(\"    â€¢ 7ê°œ ì„œë¸Œ ì—ì´ì „íŠ¸ ë³‘ë ¬ í‰ê°€ (2ì°¨ ì›Œí¬ìƒµ)\")\n",
    "print(\"    â€¢ ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\")\n",
    "print(\"    â€¢ 45ê°œ ì–¸ì–´ í™•ì¥ ì ìš©\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
