{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Lab 6: í”¼ë“œë°± ê¸°ë°˜ ì¬ë²ˆì—­\n",
    "\n",
    "\n",
    "\n",
    " Lab 3-5 í‰ê°€ ê²°ê³¼ì™€ US/GB ì§€ì—­ íƒ€ê²ŸíŒ…ì„ í™œìš©í•˜ì—¬ ë ˆí¼ëŸ°ìŠ¤ì— ê°€ê¹Œìš´ ë²ˆì—­ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    " ## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "\n",
    "\n",
    " - ë ˆí¼ëŸ°ìŠ¤ ë°ì´í„°ì—ì„œ ìš©ì–´ì§‘/ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ìë™ ì¶”ì¶œ\n",
    "\n",
    " - í‰ê°€ í”¼ë“œë°±ì„ í™œìš©í•œ ë²ˆì—­ í’ˆì§ˆ ê°œì„ \n",
    "\n",
    " - ì¬ë²ˆì—­ í›„ ì¶©ì‹¤ë„/ìš©ì–´/í†¤ ì¬í‰ê°€ë¡œ ê°œì„  í™•ì¸\n",
    "\n",
    "\n",
    "\n",
    " ## ì›Œí¬ìƒµ ì „ì²´ íë¦„\n",
    "\n",
    "\n",
    "\n",
    " ```\n",
    "\n",
    " Lab 1: í™˜ê²½ ì„¤ì • âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 2: ë²ˆì—­ ê¸°ë²• ë¹„êµ âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 3: í’ˆì§ˆ í‰ê°€ - ì¶©ì‹¤ë„ âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 4: í’ˆì§ˆ í‰ê°€ - ìš©ì–´ ì¼ê´€ì„± âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 5: í’ˆì§ˆ í‰ê°€ - ë¬¸í™”/í†¤ âœ…\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 6: í”¼ë“œë°± ê¸°ë°˜ ì¬ë²ˆì—­ (í˜„ì¬)\n",
    "\n",
    " â†“\n",
    "\n",
    " Lab 7: ì¢…í•© ë¶„ì„\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.1 í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ì‚¬ìš© ëª¨ë¸: Claude Sonnet 4\n"
     ]
    }
   ],
   "source": [
    "REGION = \"us-west-2\"\n",
    "OUTPUT_DIR = \"lab_outputs\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=REGION\n",
    ")\n",
    "\n",
    "CLAUDE_MODELS = {\n",
    "    \"sonnet\": {\n",
    "        \"id\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "        \"name\": \"Claude Sonnet 4\",\n",
    "    },\n",
    "    \"haiku\": {\n",
    "        \"id\": \"us.anthropic.claude-haiku-4-20250514-v1:0\",\n",
    "        \"name\": \"Claude Haiku 4\",\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFAULT_MODEL = \"sonnet\"\n",
    "MODEL_ID = CLAUDE_MODELS[DEFAULT_MODEL][\"id\"]\n",
    "\n",
    "print(f\"Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"ì‚¬ìš© ëª¨ë¸: {CLAUDE_MODELS[DEFAULT_MODEL]['name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(filename: str) -> dict:\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_json(filename: str) -> dict:\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_results(data: dict, filename: str) -> str:\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    data[\"_metadata\"] = {\n",
    "        \"saved_at\": datetime.now().isoformat(),\n",
    "        \"model\": CLAUDE_MODELS[DEFAULT_MODEL][\"name\"]\n",
    "    }\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ“ ì €ì¥ ì™„ë£Œ: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def call_claude(prompt: str, model_id: str = MODEL_ID, max_tokens: int = 2048) -> str:\n",
    "    request_body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(request_body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    return response_body[\"content\"][0][\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›Œí¬ìƒµ FAQ í•­ëª©: 6ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "workshop_config = load_results(\"workshop_config.json\")\n",
    "faithfulness_data = load_results(\"eval_faithfulness.json\")\n",
    "terminology_data = load_results(\"eval_terminology.json\")\n",
    "culture_tone_data = load_results(\"eval_culture_tone.json\")\n",
    "\n",
    "ko_faq = load_json(\"ko_faq.json\")\n",
    "en_us_faq = load_json(\"en-rUS_faq.json\")\n",
    "en_gb_faq = load_json(\"en-rGB_faq.json\")\n",
    "\n",
    "faq_items = workshop_config[\"faq_items\"]\n",
    "print(f\"ì›Œí¬ìƒµ FAQ í•­ëª©: {len(faq_items)}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.2 ë ˆí¼ëŸ°ìŠ¤ì—ì„œ ìš©ì–´ì§‘ ìë™ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOSSARY_EXTRACTION_PROMPT = \"\"\"í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ ìŒì„ ë¶„ì„í•˜ì—¬ ìš©ì–´ì§‘ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## ë²ˆì—­ ìŒ\n",
    "{translation_pairs}\n",
    "\n",
    "## ì¶”ì¶œ ëŒ€ìƒ\n",
    "1. ë¸Œëœë“œëª… (ë²ˆì—­ ê¸ˆì§€): Samsung Cloud, Galaxy ë“±\n",
    "2. ê¸°ìˆ  ìš©ì–´: ë™ê¸°í™”, ë°±ì—…, ë³µì› ë“±\n",
    "3. UI ìš©ì–´: ì„¤ì •, íœ´ì§€í†µ ë“±\n",
    "\n",
    "ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:\n",
    "```json\n",
    "{{\n",
    "  \"brand_terms\": {{\"í•œêµ­ì–´\": \"ì˜ì–´\"}},\n",
    "  \"technical_terms\": {{\"í•œêµ­ì–´\": \"ì˜ì–´\"}},\n",
    "  \"ui_terms\": {{\"í•œêµ­ì–´\": \"ì˜ì–´\"}}\n",
    "}}\n",
    "```\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glossary(ko_data: dict, en_data: dict, locale: str) -> dict:\n",
    "    pairs = []\n",
    "    for key in list(ko_data.keys())[:20]:\n",
    "        if key in en_data and ko_data[key] and en_data[key]:\n",
    "            pairs.append(f\"í•œêµ­ì–´: {ko_data[key]}\\nì˜ì–´: {en_data[key]}\")\n",
    "    \n",
    "    prompt = GLOSSARY_EXTRACTION_PROMPT.format(translation_pairs=\"\\n\\n\".join(pairs))\n",
    "    response = call_claude(prompt)\n",
    "    \n",
    "    try:\n",
    "        if \"```json\" in response:\n",
    "            json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = response.strip()\n",
    "\n",
    "        data = json.loads(json_str)\n",
    "        combined = {}\n",
    "        for category in data.values():\n",
    "            if isinstance(category, dict):\n",
    "                combined.update(category)\n",
    "        return {\"locale\": locale, \"glossary\": combined, \"categories\": data}\n",
    "    except:\n",
    "        return {\"locale\": locale, \"glossary\": {}, \"categories\": {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US ì˜ì–´ ìš©ì–´ì§‘ ì¶”ì¶œ ì¤‘...\n",
      "US ì˜ì–´ ìš©ì–´ì§‘:\n",
      "  ì‚¼ì„± í´ë¼ìš°ë“œ â†’ Samsung Cloud\n",
      "  ì‚¼ì„± ê³„ì • â†’ Samsung account\n",
      "  ì‚¼ì„± ì¸í„°ë„· â†’ Samsung Internet\n",
      "  Samsung Notes â†’ Samsung Notes\n",
      "  Samsung Pass â†’ Samsung Pass\n",
      "  Samsung Daily â†’ Samsung Daily\n",
      "  ë™ê¸°í™” â†’ synchronization/sync\n",
      "  ë°±ì—… â†’ backup\n",
      "  ë³µì› â†’ restore\n",
      "  ë°±ì—…/ë³µì› â†’ backup/restore\n",
      "  ì—°ë™ â†’ linked\n",
      "  ì„œë²„ â†’ server\n",
      "  ë°ì´í„° â†’ data\n",
      "  OS â†’ OS\n",
      "  RAM â†’ RAM\n",
      "  S/W â†’ software\n",
      "  ì„¤ì • â†’ Settings\n",
      "  ì¼ì • â†’ Events\n",
      "  ìº˜ë¦°ë” â†’ Calendar\n",
      "  ì—°ë½ì²˜ â†’ Contacts\n",
      "  ê°¤ëŸ¬ë¦¬ â†’ Gallery\n",
      "  ë¦¬ë§ˆì¸ë” â†’ Reminders\n",
      "  AR ì´ëª¨ì§€ â†’ AR emojis\n",
      "  í†µí™” ê¸°ë¡ â†’ Call logs\n",
      "  ì‹œê³„ â†’ Clock settings\n",
      "  ë©”ì‹œì§€ â†’ Messages\n",
      "  í™ˆ í™”ë©´ â†’ Home screen layout\n",
      "  ì• í”Œë¦¬ì¼€ì´ì…˜ â†’ Apps\n",
      "  ë‹¨ë§ì˜ ì„¤ì • â†’ Device settings\n",
      "  ìŒì„± ë…¹ìŒ â†’ Voice recordings\n",
      "  ë” ë³´ê¸° â†’ More\n",
      "  ì•±ìŠ¤ í™”ë©´ â†’ Apps screen\n",
      "  Contact us â†’ Contact us\n",
      "  1ëŒ€1 ë¬¸ì˜í•˜ê¸° â†’ 1:1 inquiry\n",
      "âœ“ ì €ì¥ ì™„ë£Œ: lab_outputs/glossary_us.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lab_outputs/glossary_us.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"US ì˜ì–´ ìš©ì–´ì§‘ ì¶”ì¶œ ì¤‘...\")\n",
    "us_glossary_data = extract_glossary(ko_faq, en_us_faq, \"US\")\n",
    "\n",
    "print(\"US ì˜ì–´ ìš©ì–´ì§‘:\")\n",
    "for ko, en in us_glossary_data[\"glossary\"].items():\n",
    " print(f\"  {ko} â†’ {en}\")\n",
    "\n",
    "save_results(us_glossary_data, \"glossary_us.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.3 ë ˆí¼ëŸ°ìŠ¤ì—ì„œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ìë™ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_EXTRACTION_PROMPT = \"\"\"ì˜ì–´ ë²ˆì—­ë³¸ì„ ë¶„ì„í•˜ì—¬ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## ìƒ˜í”Œ\n",
    "{samples}\n",
    "\n",
    "ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:\n",
    "```json\n",
    "{{\n",
    "  \"spelling_rules\": [\"ê·œì¹™\"],\n",
    "  \"tone\": \"í†¤ ì„¤ëª…\",\n",
    "  \"pronoun_usage\": \"ì¸ì¹­ íŒ¨í„´\",\n",
    "  \"summary\": \"ìš”ì•½ (í•œêµ­ì–´)\"\n",
    "}}\n",
    "```\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_style_guide(en_data: dict, locale: str) -> dict:\n",
    "    samples = [f\"- {s}\" for s in list(en_data.values())[:15] if s]\n",
    "    prompt = STYLE_EXTRACTION_PROMPT.format(samples=\"\".join(samples))\n",
    "    response = call_claude(prompt)\n",
    "\n",
    "    try:\n",
    "        if \"```json\" in response:\n",
    "            json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = response.strip()\n",
    "        return {\"locale\": locale, \"style_guide\": json.loads(json_str)}\n",
    "    except:\n",
    "        return {\"locale\": locale, \"style_guide\": {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ì¶œ ì¤‘...\n",
      "\n",
      "US ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ:\n",
      "  spelling_rules: ['ì œí’ˆëª…ì€ ì •í™•í•œ ê³µì‹ ëª…ì¹­ ì‚¬ìš© (Samsung Cloud, Samsung Internet, Samsung Notes, Samsung Pass, Samsung Daily)', 'ê¸°ìˆ  ìš©ì–´ì˜ ì¼ê´€ëœ í‘œê¸° (sync/backup, backup/restore)', \"ë©”ë‰´ ê²½ë¡œëŠ” '>' ê¸°í˜¸ë¡œ êµ¬ë¶„ (Settings > Samsung Account > Samsung Cloud)\", 'ê´„í˜¸ë¥¼ ì‚¬ìš©í•œ ë¶€ê°€ ì„¤ëª… ì œê³µ (Events (Calendar), version 3.X or higher)', 'í•˜ì´í”ˆì„ ì‚¬ìš©í•œ ëª©ë¡ êµ¬ì¡°í™”', 'ì§ˆë¬¸ í˜•íƒœì˜ ì†Œì œëª©ì— ë¬¼ìŒí‘œ ì‚¬ìš©']\n",
      "  tone: ê³µì‹ì ì´ê³  ì„¤ëª…ì ì¸ í†¤. ê¸°ìˆ  ë¬¸ì„œì˜ íŠ¹ì„±ìƒ ê°ê´€ì ì´ê³  ì •í™•í•œ ì •ë³´ ì „ë‹¬ì— ì¤‘ì ì„ ë‘” formalí•œ ì–´ì¡°\n",
      "  pronoun_usage: 2ì¸ì¹­ 'you/your' ì¤‘ì‹¬ ì‚¬ìš©ìœ¼ë¡œ ì‚¬ìš©ìì™€ì˜ ì§ì ‘ì  ì†Œí†µ. 1ì¸ì¹­ì€ ê±°ì˜ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©°, ì‚¬ìš©ì ê´€ì ì—ì„œ ì„œìˆ \n",
      "  summary: Samsung Cloud ì„œë¹„ìŠ¤ì— ëŒ€í•œ ê¸°ìˆ  ë¬¸ì„œë¡œ, ì œí’ˆ ê¸°ëŠ¥ ì„¤ëª…ê³¼ FAQ í˜•ì‹ì„ ê²°í•©í•œ ì‚¬ìš©ì ê°€ì´ë“œ. ê³µì‹ì ì´ë©´ì„œë„ ì ‘ê·¼í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ë³µì¡í•œ ê¸°ìˆ ì  ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ì œì‹œí•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ë³´ì„\n",
      "âœ“ ì €ì¥ ì™„ë£Œ: lab_outputs/style_guide_us.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lab_outputs/style_guide_us.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"US ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ì¶œ ì¤‘...\")\n",
    "us_style_data = extract_style_guide(en_us_faq, \"US\")\n",
    "\n",
    "print(\"\\nUS ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ:\")\n",
    "for key, value in us_style_data[\"style_guide\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "save_results(us_style_data, \"style_guide_us.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.4 í‰ê°€ í”¼ë“œë°± ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(item_id: str) -> str:\n",
    "    parts = []\n",
    "    \n",
    "    for e in faithfulness_data.get(\"glossary\", []):\n",
    "        if e[\"id\"] == item_id and e.get(\"issues\"):\n",
    "            parts.append(f\"[ì¶©ì‹¤ë„] {', '.join(e['issues'])}\")\n",
    "    \n",
    "    for e in terminology_data.get(\"glossary\", []):\n",
    "        if e[\"id\"] == item_id and e.get(\"issues\"):\n",
    "            parts.append(f\"[ìš©ì–´] {', '.join(e['issues'])}\")\n",
    "    \n",
    "    for e in culture_tone_data.get(\"glossary\", []):\n",
    "        if e[\"id\"] == item_id and e.get(\"issues\"):\n",
    "            parts.append(f\"[í†¤] {', '.join(e['issues'])}\")\n",
    "    \n",
    "    return \"\\n\".join(parts) if parts else \"íŠ¹ë³„í•œ ë¬¸ì œì  ì—†ìŒ\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.5 US ì˜ì–´ íƒ€ê²ŸíŒ… ë²ˆì—­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION_PROMPT = \"\"\"ì‚¼ì„± ê³µì‹ ë²ˆì—­ê°€ë¡œì„œ í•œêµ­ì–´ë¥¼ {locale} ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## ì›ë¬¸\n",
    "{source}\n",
    "\n",
    "## ìŠ¤íƒ€ì¼ ê°€ì´ë“œ\n",
    "{style_guide}\n",
    "\n",
    "## ìš©ì–´ì§‘\n",
    "{glossary}\n",
    "\n",
    "## ì´ì „ í”¼ë“œë°±\n",
    "{feedback}\n",
    "\n",
    "ë²ˆì—­ ê²°ê³¼ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_targeted(source: str, item_id: str, glossary: dict, style: dict, locale: str) -> str:\n",
    "    glossary_text = \"\\n\".join([f\"- {k} â†’ {v}\" for k, v in glossary.items()])\n",
    "    style_text = style.get(\"summary\", \"\")\n",
    "    \n",
    "    prompt = TRANSLATION_PROMPT.format(\n",
    "        locale=locale,\n",
    "        source=source,\n",
    "        style_guide=style_text,\n",
    "        glossary=glossary_text,\n",
    "        feedback=get_feedback(item_id)\n",
    "    )\n",
    "    return call_claude(prompt).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US ì˜ì–´ ë²ˆì—­ ì‹¤í–‰ ì¤‘...\n",
      "================================================================================\n",
      "\n",
      "[IDS_FAQ_SC_MAIN_HEADER_02]\n",
      "ë²ˆì—­: Do I need a Samsung account to use Samsung Cloud?\n",
      "ì°¸ì¡°: Do I need a Samsung account to use Samsung Cloud?\n",
      "\n",
      "[IDS_FAQ_SC_MAIN_HEADER_03]\n",
      "ë²ˆì—­: What happens if I remove my Samsung account from the device?\n",
      "ì°¸ì¡°: What happens if I remove my Samsung account?\n",
      "\n",
      "[IDS_FAQ_SC_ACCESSING_TEXT]\n",
      "ë²ˆì—­: After accessing the Samsung Cloud webpage, please contact us through Contact us using \"1:1 inquiry.\" We can unblock access after verifying your user information.\n",
      "ì°¸ì¡°: After accessing the Samsung Cloud web page, contact us through the \"1:1 inquiry\" in \"Contact us\". We will unlock your Samsung Cloud after confirming your user information.\n",
      "\n",
      "[IDS_FAQ_SC_MAIN_HEADER_13]\n",
      "ë²ˆì—­: I don't currently have a Galaxy device. Is there a way to check my data or information that was stored and synced to Samsung services?\n",
      "ì°¸ì¡°: I do not have a Galaxy device now. Is there a way to check my data or information stored and synchronized with Samsung services?\n",
      "\n",
      "[IDS_FAQ_GO_DEVICE_NOTES_UL_01]\n",
      "ë²ˆì—­: Support may vary depending on the device, country, or carrier.\n",
      "ì°¸ì¡°: Not supported on certain devices, carriers' devices, or in certain countries.\n",
      "\n",
      "[IDS_FAQ_GO_MAIN_HEADER_27]\n",
      "ë²ˆì—­: Where can I check the Cloud Trash?\n",
      "ì°¸ì¡°: Where can I find my Cloud Trash?\n"
     ]
    }
   ],
   "source": [
    "us_translations = []\n",
    "\n",
    "print(\"US ì˜ì–´ ë²ˆì—­ ì‹¤í–‰ ì¤‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for item in faq_items:\n",
    "    translation = translate_targeted(\n",
    "        item[\"ko\"], item[\"id\"],\n",
    "        us_glossary_data[\"glossary\"],\n",
    "        us_style_data[\"style_guide\"],\n",
    "        \"US\"\n",
    "    )\n",
    "    \n",
    "    us_translations.append({\n",
    "        \"id\": item[\"id\"],\n",
    "        \"source\": item[\"ko\"],\n",
    "        \"translation\": translation,\n",
    "        \"reference\": en_us_faq.get(item[\"id\"], \"\"),\n",
    "        \"locale\": \"US\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n[{item['id']}]\")\n",
    "    print(f\"ë²ˆì—­: {translation}\")\n",
    "    print(f\"ì°¸ì¡°: {en_us_faq.get(item['id'], '')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.6 US ë²ˆì—­ ë ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_EVAL_PROMPT = \"\"\"ë²ˆì—­ë¬¸ê³¼ ë ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì›ë¬¸: {source}\n",
    "ë²ˆì—­: {translation}\n",
    "ë ˆí¼ëŸ°ìŠ¤: {reference}\n",
    "\n",
    "ì ìˆ˜: 5=ê±°ì˜ë™ì¼, 4=ì˜ë¯¸ë™ì¼, 3=ìœ ì‚¬, 0-2=ë‹¤ë¦„\n",
    "\n",
    "JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:\n",
    "```json\n",
    "{{\"score\": <0-5>, \"differences\": [\"ì°¨ì´ì \"], \"reasoning\": \"ê·¼ê±°\"}}\n",
    "```\"\"\"\n",
    "\n",
    "def eval_similarity(source: str, translation: str, reference: str) -> dict:\n",
    "    prompt = SIMILARITY_EVAL_PROMPT.format(source=source, translation=translation, reference=reference)\n",
    "    response = call_claude(prompt)\n",
    "    \n",
    "    try:\n",
    "        if \"```json\" in response:\n",
    "            json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = response.strip()\n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return {\"score\": 0, \"differences\": [\"íŒŒì‹±ì‹¤íŒ¨\"], \"reasoning\": \"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US ë²ˆì—­ ìœ ì‚¬ë„ í‰ê°€ ì¤‘...\n",
      "[IDS_FAQ_SC_MAIN_HEADER_02] ìœ ì‚¬ë„: 5/5\n",
      "[IDS_FAQ_SC_MAIN_HEADER_03] ìœ ì‚¬ë„: 4/5\n",
      "[IDS_FAQ_SC_ACCESSING_TEXT] ìœ ì‚¬ë„: 4/5\n",
      "[IDS_FAQ_SC_MAIN_HEADER_13] ìœ ì‚¬ë„: 4/5\n",
      "[IDS_FAQ_GO_DEVICE_NOTES_UL_01] ìœ ì‚¬ë„: 3/5\n",
      "[IDS_FAQ_GO_MAIN_HEADER_27] ìœ ì‚¬ë„: 4/5\n"
     ]
    }
   ],
   "source": [
    "print(\"US ë²ˆì—­ ìœ ì‚¬ë„ í‰ê°€ ì¤‘...\")\n",
    "\n",
    "us_similarity_evals = []\n",
    "for item in us_translations:\n",
    " result = eval_similarity(item[\"source\"], item[\"translation\"], item[\"reference\"])\n",
    " us_similarity_evals.append({\"id\": item[\"id\"], **result})\n",
    " print(f\"[{item['id']}] ìœ ì‚¬ë„: {result['score']}/5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.7 US ë²ˆì—­ í’ˆì§ˆ ì¬í‰ê°€ (ì¶©ì‹¤ë„/ìš©ì–´/í†¤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶©ì‹¤ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸\n",
    "FAITHFULNESS_PROMPT = \"\"\"ì›ë¬¸ê³¼ ë²ˆì—­ì˜ ì¶©ì‹¤ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì›ë¬¸: {source}\n",
    "ë²ˆì—­: {translation}\n",
    "\n",
    "ì ìˆ˜: 5=ì™„ë²½, 4=ê²½ë¯¸ì°¨ì´, 3=ì¼ë¶€ëˆ„ë½, 0-2=ì˜¤ë¥˜\n",
    "\n",
    "JSON í˜•ì‹:\n",
    "```json\n",
    "{{\"score\": <0-5>, \"issues\": [\"ë¬¸ì œì \"], \"reasoning\": \"ê·¼ê±°\"}}\n",
    "```\"\"\"\n",
    "\n",
    "# ìš©ì–´ í‰ê°€ í”„ë¡¬í”„íŠ¸\n",
    "TERMINOLOGY_PROMPT = \"\"\"ìš©ì–´ì§‘ ì¤€ìˆ˜ ì—¬ë¶€ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë²ˆì—­: {translation}\n",
    "ìš©ì–´ì§‘: {glossary}\n",
    "\n",
    "ì ìˆ˜: 5=ì™„ë²½ì¤€ìˆ˜, 4=ê²½ë¯¸ìœ„ë°˜, 3=ë‹¤ìˆ˜ìœ„ë°˜, 0-2=ì‹¬ê°ìœ„ë°˜\n",
    "\n",
    "JSON í˜•ì‹:\n",
    "```json\n",
    "{{\"score\": <0-5>, \"issues\": [\"ë¬¸ì œì \"], \"reasoning\": \"ê·¼ê±°\"}}\n",
    "```\"\"\"\n",
    "\n",
    "# í†¤ í‰ê°€ í”„ë¡¬í”„íŠ¸\n",
    "TONE_PROMPT = \"\"\"ë²ˆì—­ì˜ í†¤ê³¼ ìŠ¤íƒ€ì¼ì„ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë²ˆì—­: {translation}\n",
    "ìŠ¤íƒ€ì¼ê°€ì´ë“œ: {style_guide}\n",
    "\n",
    "ì ìˆ˜: 5=ì™„ë²½, 4=ê²½ë¯¸ì°¨ì´, 3=ë¶ˆì¼ì¹˜, 0-2=ë¶€ì ì ˆ\n",
    "\n",
    "JSON í˜•ì‹:\n",
    "```json\n",
    "{{\"score\": <0-5>, \"issues\": [\"ë¬¸ì œì \"], \"reasoning\": \"ê·¼ê±°\"}}\n",
    "```\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_faithfulness(source: str, translation: str) -> dict:\n",
    "    prompt = FAITHFULNESS_PROMPT.format(source=source, translation=translation)\n",
    "    response = call_claude(prompt)\n",
    "    try:\n",
    "        if \"```json\" in response:\n",
    "                json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = response.strip()\n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return {\"score\": 0, \"issues\": [\"íŒŒì‹±ì‹¤íŒ¨\"], \"reasoning\": \"\"}\n",
    "\n",
    "def eval_terminology(translation: str, glossary: dict) -> dict:\n",
    "    glossary_text = \"\\n\".join([f\"- {k} â†’ {v}\" for k, v in glossary.items()])\n",
    "    prompt = TERMINOLOGY_PROMPT.format(translation=translation, glossary=glossary_text)\n",
    "    response = call_claude(prompt)\n",
    "    try:\n",
    "        if \"```json\" in response:\n",
    "            json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = response.strip()\n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return {\"score\": 0, \"issues\": [\"íŒŒì‹±ì‹¤íŒ¨\"], \"reasoning\": \"\"}\n",
    "\n",
    "def eval_tone(translation: str, style_guide: dict) -> dict:\n",
    "    style_text = style_guide.get(\"summary\", \"\")\n",
    "    prompt = TONE_PROMPT.format(translation=translation, style_guide=style_text)\n",
    "    response = call_claude(prompt)\n",
    "    try:\n",
    "        if \"```json\" in response:\n",
    "            json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = response.strip()\n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return {\"score\": 0, \"issues\": [\"íŒŒì‹±ì‹¤íŒ¨\"], \"reasoning\": \"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "US ë²ˆì—­ í’ˆì§ˆ ì¬í‰ê°€ ì¤‘ (ì¶©ì‹¤ë„/ìš©ì–´/í†¤)...\n",
      "================================================================================\n",
      "\n",
      "[IDS_FAQ_SC_MAIN_HEADER_02]\n",
      "  ì¶©ì‹¤ë„: 5/5\n",
      "  ìš©ì–´: 5/5\n",
      "  í†¤: 5/5\n",
      "\n",
      "[IDS_FAQ_SC_MAIN_HEADER_03]\n",
      "  ì¶©ì‹¤ë„: 5/5\n",
      "  ìš©ì–´: 5/5\n",
      "  í†¤: 2/5\n",
      "\n",
      "[IDS_FAQ_SC_ACCESSING_TEXT]\n",
      "  ì¶©ì‹¤ë„: 4/5\n",
      "  ìš©ì–´: 5/5\n",
      "  í†¤: 2/5\n",
      "\n",
      "[IDS_FAQ_SC_MAIN_HEADER_13]\n",
      "  ì¶©ì‹¤ë„: 5/5\n",
      "  ìš©ì–´: 5/5\n",
      "  í†¤: 2/5\n",
      "\n",
      "[IDS_FAQ_GO_DEVICE_NOTES_UL_01]\n",
      "  ì¶©ì‹¤ë„: 4/5\n",
      "  ìš©ì–´: 5/5\n",
      "  í†¤: 4/5\n",
      "\n",
      "[IDS_FAQ_GO_MAIN_HEADER_27]\n",
      "  ì¶©ì‹¤ë„: 4/5\n",
      "  ìš©ì–´: 2/5\n",
      "  í†¤: 4/5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUS ë²ˆì—­ í’ˆì§ˆ ì¬í‰ê°€ ì¤‘ (ì¶©ì‹¤ë„/ìš©ì–´/í†¤)...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "us_quality_evals = []\n",
    "\n",
    "for item in us_translations:\n",
    "    faith = eval_faithfulness(item[\"source\"], item[\"translation\"])\n",
    "    term = eval_terminology(item[\"translation\"], us_glossary_data[\"glossary\"])\n",
    "    tone = eval_tone(item[\"translation\"], us_style_data[\"style_guide\"])\n",
    "    \n",
    "    us_quality_evals.append({\n",
    "        \"id\": item[\"id\"],\n",
    "        \"faithfulness\": faith,\n",
    "        \"terminology\": term,\n",
    "        \"tone\": tone\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n[{item['id']}]\")\n",
    "    print(f\"  ì¶©ì‹¤ë„: {faith['score']}/5\")\n",
    "    print(f\"  ìš©ì–´: {term['score']}/5\")\n",
    "    print(f\"  í†¤: {tone['score']}/5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.8 US ë²ˆì—­ ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "US ì˜ì–´ ë²ˆì—­ ê²°ê³¼ ìš”ì•½\n",
      "================================================================================\n",
      "\n",
      "ë ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„: 4.00/5\n",
      "ì¶©ì‹¤ë„: 4.50/5\n",
      "ìš©ì–´ ì¼ê´€ì„±: 4.50/5\n",
      "í†¤/ìŠ¤íƒ€ì¼: 3.17/5\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì ìˆ˜ ê³„ì‚°\n",
    "similarity_avg = sum(e[\"score\"] for e in us_similarity_evals) / len(us_similarity_evals)\n",
    "faith_avg = sum(e[\"faithfulness\"][\"score\"] for e in us_quality_evals) / len(us_quality_evals)\n",
    "term_avg = sum(e[\"terminology\"][\"score\"] for e in us_quality_evals) / len(us_quality_evals)\n",
    "tone_avg = sum(e[\"tone\"][\"score\"] for e in us_quality_evals) / len(us_quality_evals)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"US ì˜ì–´ ë²ˆì—­ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\në ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„: {similarity_avg:.2f}/5\")\n",
    "print(f\"ì¶©ì‹¤ë„: {faith_avg:.2f}/5\")\n",
    "print(f\"ìš©ì–´ ì¼ê´€ì„±: {term_avg:.2f}/5\")\n",
    "print(f\"í†¤/ìŠ¤íƒ€ì¼: {tone_avg:.2f}/5\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ì €ì¥ ì™„ë£Œ: lab_outputs/translations_us_targeted.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lab_outputs/translations_us_targeted.json'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê²°ê³¼ ì €ì¥\n",
    "save_results({\n",
    "    \"translations\": us_translations,\n",
    "    \"similarity_evals\": us_similarity_evals,\n",
    "    \"quality_evals\": us_quality_evals,\n",
    "    \"summary\": {\n",
    "        \"similarity_avg\": similarity_avg,\n",
    "        \"faithfulness_avg\": faith_avg,\n",
    "        \"terminology_avg\": term_avg,\n",
    "        \"tone_avg\": tone_avg\n",
    "    },\n",
    "    \"glossary\": us_glossary_data[\"glossary\"],\n",
    "    \"style_guide\": us_style_data[\"style_guide\"]\n",
    "}, \"translations_us_targeted.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.9 ğŸ¯ ë¯¸ì…˜: GB ì˜ì–´ íƒ€ê²ŸíŒ… ë²ˆì—­\n",
    "\n",
    "\n",
    "\n",
    " US ì˜ì–´ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ GB ì˜ì–´ ë²ˆì—­ì„ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "\n",
    " ë ˆí¼ëŸ°ìŠ¤(en-rGB_faq.json)ì—ì„œ ìš©ì–´ì§‘ê³¼ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ë¯¸ì…˜ 1: GB ì˜ì–´ ìš©ì–´ì§‘ ìë™ ì¶”ì¶œ\n",
    "\n",
    "\n",
    "\n",
    " íŒíŠ¸: `extract_glossary(ko_faq, en_gb_faq, \"GB\")` ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB ì˜ì–´ ìš©ì–´ì§‘ ì¶”ì¶œ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "print(\"GB ì˜ì–´ ìš©ì–´ì§‘ ì¶”ì¶œ ì¤‘...\")\n",
    "\n",
    "# gb_glossary_data = extract_glossary(???, ???, ???)\n",
    "\n",
    "# print(\"\\nGB ì˜ì–´ ìš©ì–´ì§‘:\")\n",
    "# for ko, en in gb_glossary_data[\"glossary\"].items():\n",
    "#     print(f\"  {ko} â†’ {en}\")\n",
    "\n",
    "# save_results(gb_glossary_data, \"glossary_gb.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ë¯¸ì…˜ 2: GB ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ìë™ ì¶”ì¶œ\n",
    "\n",
    "\n",
    "\n",
    " íŒíŠ¸: `extract_style_guide(en_gb_faq, \"GB\")` ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ì¶œ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "print(\"GB ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ì¶œ ì¤‘...\")\n",
    "\n",
    "# gb_style_data = extract_style_guide(???, ???)\n",
    "\n",
    "# print(\"\\nGB ì˜ì–´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ:\")\n",
    "# for key, value in gb_style_data[\"style_guide\"].items():\n",
    "#     print(f\"  {key}: {value}\")\n",
    "\n",
    "# save_results(gb_style_data, \"style_guide_gb.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ë¯¸ì…˜ 3: US vs GB ìš©ì–´ì§‘ ì°¨ì´ ë¹„êµ\n",
    "\n",
    "\n",
    "\n",
    " ì¶”ì¶œëœ USì™€ GB ìš©ì–´ì§‘ì„ ë¹„êµí•˜ì—¬ ì°¨ì´ì ì„ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "US vs GB ìš©ì–´ì§‘ ì°¨ì´\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "print(\"=\" * 80)\n",
    "print(\"US vs GB ìš©ì–´ì§‘ ì°¨ì´\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# us_glossary = us_glossary_data[\"glossary\"]\n",
    "# gb_glossary = gb_glossary_data[\"glossary\"]\n",
    "\n",
    "# all_keys = set(us_glossary.keys()) | set(gb_glossary.keys())\n",
    "# for ko in all_keys:\n",
    "#     us_term = us_glossary.get(ko, \"-\")\n",
    "#     gb_term = gb_glossary.get(ko, \"-\")\n",
    "#     if us_term != gb_term:\n",
    "#         print(f\"  {ko}: US={us_term}, GB={gb_term}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ë¯¸ì…˜ 4: GB ì˜ì–´ ë²ˆì—­ ì‹¤í–‰\n",
    "\n",
    "\n",
    "\n",
    " íŒíŠ¸: `translate_targeted()` í•¨ìˆ˜ì— GB ìš©ì–´ì§‘ê³¼ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì „ë‹¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB ì˜ì–´ ë²ˆì—­ ì‹¤í–‰ ì¤‘...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "gb_translations = []\n",
    "\n",
    "print(\"GB ì˜ì–´ ë²ˆì—­ ì‹¤í–‰ ì¤‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# for item in faq_items:\n",
    "#     translation = translate_targeted(\n",
    "#         item[\"ko\"], item[\"id\"],\n",
    "#         ???,  # GB ìš©ì–´ì§‘\n",
    "#         ???,  # GB ìŠ¤íƒ€ì¼ ê°€ì´ë“œ\n",
    "#         \"GB\"\n",
    "#     )\n",
    "#     \n",
    "#     gb_translations.append({\n",
    "#         \"id\": item[\"id\"],\n",
    "#         \"source\": item[\"ko\"],\n",
    "#         \"translation\": translation,\n",
    "#         \"reference\": en_gb_faq.get(item[\"id\"], \"\"),\n",
    "#         \"locale\": \"GB\"\n",
    "#     })\n",
    "#     \n",
    "#     print(f\"\\n[{item['id']}]\")\n",
    "#     print(f\"ë²ˆì—­: {translation}\")\n",
    "#     print(f\"ì°¸ì¡°: {en_gb_faq.get(item['id'], '')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ë¯¸ì…˜ 5: GB ë²ˆì—­ ìœ ì‚¬ë„ í‰ê°€\n",
    "\n",
    "\n",
    "\n",
    " íŒíŠ¸: `eval_similarity()` í•¨ìˆ˜ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GB ë²ˆì—­ ìœ ì‚¬ë„ í‰ê°€ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "print(\"\\nGB ë²ˆì—­ ìœ ì‚¬ë„ í‰ê°€ ì¤‘...\")\n",
    "\n",
    "gb_similarity_evals = []\n",
    "\n",
    "# for item in gb_translations:\n",
    "#     result = eval_similarity(item[\"source\"], item[\"translation\"], item[\"reference\"])\n",
    "#     gb_similarity_evals.append({\"id\": item[\"id\"], **result})\n",
    "#     print(f\"[{item['id']}] ìœ ì‚¬ë„: {result['score']}/5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ë¯¸ì…˜ 6: GB ë²ˆì—­ í’ˆì§ˆ ì¬í‰ê°€ (ì¶©ì‹¤ë„/ìš©ì–´/í†¤)\n",
    "\n",
    "\n",
    "\n",
    " íŒíŠ¸: `eval_faithfulness()`, `eval_terminology()`, `eval_tone()` í•¨ìˆ˜ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GB ë²ˆì—­ í’ˆì§ˆ ì¬í‰ê°€ ì¤‘ (ì¶©ì‹¤ë„/ìš©ì–´/í†¤)...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "print(\"\\nGB ë²ˆì—­ í’ˆì§ˆ ì¬í‰ê°€ ì¤‘ (ì¶©ì‹¤ë„/ìš©ì–´/í†¤)...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "gb_quality_evals = []\n",
    "\n",
    "# for item in gb_translations:\n",
    "#     faith = eval_faithfulness(item[\"source\"], item[\"translation\"])\n",
    "#     term = eval_terminology(item[\"translation\"], gb_glossary_data[\"glossary\"])\n",
    "#     tone = eval_tone(item[\"translation\"], gb_style_data[\"style_guide\"])\n",
    "#     \n",
    "#     gb_quality_evals.append({\n",
    "#         \"id\": item[\"id\"],\n",
    "#         \"faithfulness\": faith,\n",
    "#         \"terminology\": term,\n",
    "#         \"tone\": tone\n",
    "#     })\n",
    "#     \n",
    "#     print(f\"\\n[{item['id']}]\")\n",
    "#     print(f\"  ì¶©ì‹¤ë„: {faith['score']}/5\")\n",
    "#     print(f\"  ìš©ì–´: {term['score']}/5\")\n",
    "#     print(f\"  í†¤: {tone['score']}/5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ë¯¸ì…˜ 7: GB ë²ˆì—­ ê²°ê³¼ ìš”ì•½ ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ì•„ë˜ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "\n",
    "# GB ì ìˆ˜ ê³„ì‚°\n",
    "# gb_similarity_avg = sum(e[\"score\"] for e in gb_similarity_evals) / len(gb_similarity_evals)\n",
    "# gb_faith_avg = sum(e[\"faithfulness\"][\"score\"] for e in gb_quality_evals) / len(gb_quality_evals)\n",
    "# gb_term_avg = sum(e[\"terminology\"][\"score\"] for e in gb_quality_evals) / len(gb_quality_evals)\n",
    "# gb_tone_avg = sum(e[\"tone\"][\"score\"] for e in gb_quality_evals) / len(gb_quality_evals)\n",
    "\n",
    "# print(\"=\" * 80)\n",
    "# print(\"GB ì˜ì–´ ë²ˆì—­ ê²°ê³¼ ìš”ì•½\")\n",
    "# print(\"=\" * 80)\n",
    "# print(f\"\\në ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„: {gb_similarity_avg:.2f}/5\")\n",
    "# print(f\"ì¶©ì‹¤ë„: {gb_faith_avg:.2f}/5\")\n",
    "# print(f\"ìš©ì–´ ì¼ê´€ì„±: {gb_term_avg:.2f}/5\")\n",
    "# print(f\"í†¤/ìŠ¤íƒ€ì¼: {gb_tone_avg:.2f}/5\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# GB ê²°ê³¼ ì €ì¥\n",
    "# save_results({\n",
    "#     \"translations\": gb_translations,\n",
    "#     \"similarity_evals\": gb_similarity_evals,\n",
    "#     \"quality_evals\": gb_quality_evals,\n",
    "#     \"summary\": {\n",
    "#         \"similarity_avg\": gb_similarity_avg,\n",
    "#         \"faithfulness_avg\": gb_faith_avg,\n",
    "#         \"terminology_avg\": gb_term_avg,\n",
    "#         \"tone_avg\": gb_tone_avg\n",
    "#     },\n",
    "#     \"glossary\": gb_glossary_data[\"glossary\"],\n",
    "#     \"style_guide\": gb_style_data[\"style_guide\"]\n",
    "# }, \"translations_gb_targeted.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.10 US vs GB ìµœì¢… ë¹„êµ\n",
    "\n",
    "\n",
    "\n",
    " ë¯¸ì…˜ì„ ì™„ë£Œí•œ í›„ ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ USì™€ GB ê²°ê³¼ë¥¼ ë¹„êµí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¯¸ì…˜ ì™„ë£Œ í›„ ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰\n",
    "# print(\"=\" * 100)\n",
    "# print(\"US vs GB íƒ€ê²ŸíŒ… ë²ˆì—­ ê²°ê³¼ ë¹„êµ\")\n",
    "# print(\"=\" * 100)\n",
    "\n",
    "# print(f\"\\n{'í‰ê°€ í•­ëª©':<20} {'US':<15} {'GB':<15}\")\n",
    "# print(\"-\" * 50)\n",
    "# print(f\"{'ë ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„':<20} {similarity_avg:<15.2f} {gb_similarity_avg:<15.2f}\")\n",
    "# print(f\"{'ì¶©ì‹¤ë„':<20} {faith_avg:<15.2f} {gb_faith_avg:<15.2f}\")\n",
    "# print(f\"{'ìš©ì–´ ì¼ê´€ì„±':<20} {term_avg:<15.2f} {gb_term_avg:<15.2f}\")\n",
    "# print(f\"{'í†¤/ìŠ¤íƒ€ì¼':<20} {tone_avg:<15.2f} {gb_tone_avg:<15.2f}\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# us_total = (similarity_avg + faith_avg + term_avg + tone_avg) / 4\n",
    "# gb_total = (gb_similarity_avg + gb_faith_avg + gb_term_avg + gb_tone_avg) / 4\n",
    "# print(f\"{'ì¢…í•© í‰ê· ':<20} {us_total:<15.2f} {gb_total:<15.2f}\")\n",
    "# print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6.11 Lab 6 ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Lab 6: í”¼ë“œë°± ê¸°ë°˜ ì¬ë²ˆì—­ ì™„ë£Œ\n",
      "================================================================================\n",
      "\n",
      "[í•µì‹¬ í•™ìŠµ ë‚´ìš©]\n",
      "  - ë ˆí¼ëŸ°ìŠ¤ ë°ì´í„°ì—ì„œ ìš©ì–´ì§‘/ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ìë™ ì¶”ì¶œ\n",
      "  - ì¶”ì¶œëœ ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•œ ì§€ì—­ë³„ íƒ€ê²ŸíŒ… ë²ˆì—­\n",
      "  - ì¬ë²ˆì—­ í›„ ì¶©ì‹¤ë„/ìš©ì–´/í†¤ ì¬í‰ê°€ë¡œ í’ˆì§ˆ ê²€ì¦\n",
      "\n",
      "[US ì˜ì–´ ê²°ê³¼]\n",
      "  - ë ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„: 4.00/5\n",
      "  - ì¶©ì‹¤ë„: 4.50/5\n",
      "  - ìš©ì–´ ì¼ê´€ì„±: 4.50/5\n",
      "  - í†¤/ìŠ¤íƒ€ì¼: 3.17/5\n",
      "\n",
      "[GB ì˜ì–´ ë¯¸ì…˜]\n",
      "  - ìœ„ ë¯¸ì…˜ë“¤ì„ ì™„ë£Œí•˜ì—¬ GB ì˜ì–´ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!\n",
      "\n",
      "[ì €ì¥ëœ íŒŒì¼]\n",
      "  - lab_outputs/glossary_us.json\n",
      "  - lab_outputs/style_guide_us.json\n",
      "  - lab_outputs/translations_us_targeted.json\n",
      "\n",
      "[ë‹¤ìŒ ë‹¨ê³„]\n",
      "  â†’ Lab 7: ì¢…í•© ë¶„ì„\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Lab 6: í”¼ë“œë°± ê¸°ë°˜ ì¬ë²ˆì—­ ì™„ë£Œ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[í•µì‹¬ í•™ìŠµ ë‚´ìš©]\")\n",
    "print(\"  - ë ˆí¼ëŸ°ìŠ¤ ë°ì´í„°ì—ì„œ ìš©ì–´ì§‘/ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ìë™ ì¶”ì¶œ\")\n",
    "print(\"  - ì¶”ì¶œëœ ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•œ ì§€ì—­ë³„ íƒ€ê²ŸíŒ… ë²ˆì—­\")\n",
    "print(\"  - ì¬ë²ˆì—­ í›„ ì¶©ì‹¤ë„/ìš©ì–´/í†¤ ì¬í‰ê°€ë¡œ í’ˆì§ˆ ê²€ì¦\")\n",
    "\n",
    "print(\"\\n[US ì˜ì–´ ê²°ê³¼]\")\n",
    "print(f\"  - ë ˆí¼ëŸ°ìŠ¤ ìœ ì‚¬ë„: {similarity_avg:.2f}/5\")\n",
    "print(f\"  - ì¶©ì‹¤ë„: {faith_avg:.2f}/5\")\n",
    "print(f\"  - ìš©ì–´ ì¼ê´€ì„±: {term_avg:.2f}/5\")\n",
    "print(f\"  - í†¤/ìŠ¤íƒ€ì¼: {tone_avg:.2f}/5\")\n",
    "\n",
    "print(\"\\n[GB ì˜ì–´ ë¯¸ì…˜]\")\n",
    "print(\"  - ìœ„ ë¯¸ì…˜ë“¤ì„ ì™„ë£Œí•˜ì—¬ GB ì˜ì–´ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "print(\"\\n[ì €ì¥ëœ íŒŒì¼]\")\n",
    "print(f\"  - {OUTPUT_DIR}/glossary_us.json\")\n",
    "print(f\"  - {OUTPUT_DIR}/style_guide_us.json\")\n",
    "print(f\"  - {OUTPUT_DIR}/translations_us_targeted.json\")\n",
    "\n",
    "print(\"\\n[ë‹¤ìŒ ë‹¨ê³„]\")\n",
    "print(\"  â†’ Lab 7: ì¢…í•© ë¶„ì„\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translation-quality-workshop (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
